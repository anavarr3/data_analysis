---
title: "data_analysis_foreclosures"
output: html_document
date: "2023-11-10"
data: https://opendata.maryland.gov/Housing/Maryland-Notices-of-Intent-to-Foreclose-by-Zip-Cod/ftsr-vapt

---
# Strongest story idea: Right now we believe the strongest story could lie in the income levels overlapping with the intent to foreclose notices or the unemployment overlap with the PG County zip codes. We did a lot of the joining work this milestone, so we don't have a complete idea yet. I'm also interested in Q5 and why there was a spike of notices around the springtime before dropping back down. We think the income levels overlapping with the intent to foreclose notices could be newsworthy if it turns out that income levels are trending downward with intent to foreclose notices trend up, and by how much. Or, is it the opposite and can people, while they have a decent income, just not afford rent/mortgages?

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#install.packages("zoo")
```

```{r}
library(tidyverse)
library(dplyr)
library(janitor)
library(zoo)
library(ggplot2)
library(tidycensus)
library(lubridate)
```
# Dataset: Maryland Notices of Intent to Foreclose (July 2021 - Oct. 2023)
```{r}
# Read in and clean the data
foreclosures <- read_csv("Maryland_Notices_of_Intent_to_Foreclose.csv") |> 
  clean_names() |> 
  rename(february_2022 = february_2020)
foreclosures
```
# Cleaning
In cleaning the data, we recognized that there was an error in the original data so we contacted the creator of the data to confirm that February 2020 was supposed to be marked February 2022. We made sure to rename the column after reading in the data and using clean_names() to take the spaces out and make the column names uniform. There wasnâ€™t any other obvious cleaning needed from what we can tell. Here's our quick map: https://datawrapper.dwcdn.net/M2Foe/2/

```{r}
# Here we wanted to try and make a quick map to see what we were looking at other than just a table of numbers.
foreclosures_sum <- foreclosures |>
  group_by(zip) |>
  summarise(foreclosures_sum = sum(across(contains("_")))) |>
  arrange(desc(foreclosures_sum))

foreclosures_sum

write_csv(foreclosures_sum, "foreclosure_sum.csv")
```
We decided to go question by question to get a better understanding of the limitations present and explore some strategies to overcome those limitations and answer the questions that we posed.

# Q1
From July '21- Oct'23 "the end of the pause on foreclosure notices", which zip code has had the most notices recorded?
**This question is pretty much addressed above by adding the number of notices across the data set, grouping the results by zip code, and arranging them in descending order. The zip code 20772 in Prince George's County (including Upper Marlboro) had the highest number over the course of this timespan. See this map for a quick vizualizeation: https://datawrapper.dwcdn.net/M2Foe/1/**

# Findings so far: We found that the zip code 20772 has the highest number of intent to foreclose notices, which is in PG County. We're currently trying to figure out how that compares to other zip codes. Transposing the data was the largest hurdle here and for the rest of the questions as we had to figure out how to format different aspects.
```{r}
foreclosures_sum |> 
  arrange(desc(foreclosures_sum))
```

#Q2 
How has have foreclosure notices in this zip code changed over time? How does this compare to the other zip codes?
**Since the dataset is already ordered chronologically, simply filtering for the zip code that had the most notices will give us an idea of how many notices were given in that zip code month-by-month. We might need to contact the data set owner again to see if he has the pre-pandemic data.**

#Findings so far: The numper of intent to foreclose notices went up across zip codes. We're trying to get the map up to show this. The question will probably focus on which zip codes saw a steeper incline. Maybe a percent difference column is needed?
```{r}
# We transposed the data set to tackle this question. We had a lot of questions for ChatGPT https://chat.openai.com/share/a3d690f6-baec-4fc7-beb2-4844daf93de6 since there was an issue with getting R to recognize the first column as the first column.

transposed_redo <- foreclosures |> 
  gather(Date, Value, -1) |> spread(key = zip, value = Value) |> 
  mutate(month_year = as.yearmon(paste(Date, "01", sep = "_"), format="%B_%Y_%d"))
transposed_redo

# Here we made another attempt at transposing to format the dates using lubridate instead of the zoo package. However we continued to run into the issue of getting a character column instead of a date. We were, however, able to solve our issue with the date column being in a weird month_year format by using the format function.
transposed_redo_2 <- foreclosures |>
  gather(date, value, -1) |>
  spread(key = zip, value = value) |>
  mutate(
    date= mdy(date),
    date = format(date, "%B_%Y"))
    #month_year = paste(month.abb[month(date)], year(date), sep = "_"))
transposed_redo_2


#Now we're just cleaning a few things up. This dataframe is specific to the zip code 20772 for each month of the year from July 2021 to October 2023, so we just renamed the 20772 column "foreclosures" and kept the date and foreclosures columns before arranging by date. Because the date column is a character rather than an actual date, it's arranged in alphabetical order. We can work with that for now and separate them if we join later. 

top_foreclosure_zip <- transposed_redo_2 |> 
  rename(foreclosures = "20772") |> 
  select(date, foreclosures) |> 
  arrange(date)

top_foreclosure_zip

```


```{r}
# Time to chart it! We should also look at the percent change of other zip codes. NOTE: Getting an error on this one. Something with the date column. Error: Discrete value supplied to continuous scale.

top_foreclosure_zip |> 
   ggplot() + 
  geom_line(aes(x= date, y=foreclosures)) +
  scale_x_continuous(breaks = 1:52) +
 labs(
    title="Foreclosure notices rose drastically in this PG County zip code",
    x = "month",
    y = "foreclosures notices issued",
    caption = "Source: Office of Financial Regulation") +
theme(
    axis.text.x = element_text(angle = 45,  hjust=1)) 
 #  geom_text(check_overlap = TRUE, size = 2, aes(label = date), hjust = 0.5, vjust = -0.5)
```

```{r}
# I want to compare the above chart to the overall pattern. Here I am just readjusting the transposed_redo data set so I can see the month_year column at the front and get rid of the original date column

transposed_redo_arranged <- transposed_redo_2 |> 
#[, c(ncol(transposed_redo_2), 1:(ncol(transposed_redo_2)-1))] |> 
 select(-date)

transposed_redo_arranged
```


```{r}
#Okay, now that we've cleaned that up a bit, let's count the sum of the rows. This first part stores the dataframe inside a new dataframe without the first column so we can add a column (mutate) that is the sum of all the other columns without pulling the date into the calculation.

col_sum <- transposed_redo_arranged |> 
  mutate(sum_col = rowSums(transposed_redo_arranged[,-1]))

#This next line creates a new dataframe, where we take our fresh one ^ and ask it to pull the new column from the end (sum_col) and place it at the front.

sum_arranged <- col_sum[, c(ncol(transposed_redo_2), 1:(ncol(col_sum)-1))]

sum_arranged
```

```{r}
# Here I'm double checking that the first row is correct
rowSums(transposed_redo_arranged[1,-1])
```

#Now let's get rid of the extra columns and make a column for the average number of foreclosure notices for each date. However, I have not weighted it for population/households per zip.

```{r}
#NOTE: Double check that this is correct as far as the average goes. As for the code, sum_arranged currently doesn't have a date column. Find a way to add that back in. col_bind?
average_foreclosures_month <- sum_arranged |> 
  mutate(average = (sum_col/552)) |> 
  select(date, sum_col, average) |> 
  arrange(desc(average))

average_foreclosures_month
```

```{r}
#NOTE: This won't work until the above is fixed.
average_foreclosures_month |> 
   ggplot() + 
  geom_line(aes(x= month_year, y=sum_col)) +
  scale_x_continuous(breaks = 1:52) +
 labs(
    title="Foreclosure notices rose drastically in this PG County zip code",
    x = "month",
    y = "total foreclosures notices issued",
    caption = "Source: Office of Financial Regulation") +
theme(
    axis.text.x = element_text(angle = 45,  hjust=1)) 
#   geom_text(check_overlap = TRUE, size = 2, aes(label = month_year), hjust = 0.5, vjust = -0.5)
```


#Q3
Using census data, what are the demographics (income) of this zip code?
**Once we join foreclosures_sum with census data (demographics/income), we can get a better idea of the population in 20772 and highlight the ones that stand out.**

#Findings so far: We have mostly focused on the joining for this portion since there was a lot to join and clean to make sure the data frames matched up.

```{r}
#Here we are using the zip from the census data to pull the population by zip. We then rename geoid, estimate and moe to zip, population and moe_pop
mdzip <- get_acs(geography="zcta", variables = "B02001_001", year=2021)
mdzip <- mdzip |>
      clean_names() |>
      #separate(name, c('county', 'state'), sep=",") |>
      rename(zip=geoid, population=estimate, moe_pop=moe) |>
      group_by(zip) |>
      arrange(desc(population))
mdzip

#Here we are now joining the foreclosures_sum dataframe (the one that shows the total number of foreclosures for each zip code) with the mdzip data frame (which we made above). We then selected only the zip, foreclosure_sum, population and moe_pop columns.
foreclosure_state_pop <- left_join(foreclosures_sum, mdzip, join_by(zip))
foreclosure_state_pop <- foreclosure_state_pop |> select(zip, foreclosures_sum, population, moe_pop)
foreclosure_state_pop


#Here we're pulling the income from the census
md_income <- get_acs(geography="zcta", variables = "B05010_001", year=2021)
md_income <- md_income |>
      clean_names() |>
      rename(zip=geoid, income=estimate, moe_inc=moe) |>
      group_by(zip) |>
      arrange(desc(income))
md_income

foreclosure_pop_income <- left_join(foreclosure_state_pop, md_income, join_by(zip)) |> 
  select(zip, foreclosures_sum, population, moe_pop, income, moe_inc)
foreclosure_pop_income 
```

Q4. During the "holiday season" (Oct-Dec), how many foreclosures occur? And where?
**Limitations: we can only look at the data for 2021 and 2022 to compare the holiday season foreclosures since the 2023 data is not in yet**

NEW QUESTION: How do the unemployment rates across PG County compare to the intent to foreclose notices for each month?

#Findings so far: Again, we focused mostly on joining the dataframes here. We did find that there are some PG Counties that we don't have data for in the original data frame, however. That could pose a problem. For now, we left them out of the equation.

```{r}
#This is from the holiday question
# Here we created a separate dataframe focusing on 2021 and 2022 so we could parse through the data that qualifies for Question 4
twoyearforeclosures <- foreclosures |> 
  group_by(zip) |>
  select(ends_with("1")|ends_with("2"))
  
twoyearforeclosures
```
# New Join Data

```{r}
#Here we're loading the unemployment rate data, cleaning it and joining it to the transposed_redo_2 dataframe, joining it by the date column. We then selected the zip codes that were specific to PG County.

#Cleaning
pg_unemployment_rate <- read_csv("pg_unemployment_rate.csv") |>
  clean_names() |> 
  rename(pg_unemployment=mdprin5urn) |>
  mutate(date = format(date, "%B_%Y"))

#Here we are trying to isolate just the years 2021, 2022 and 2023
multiple_years <- c(2021, 2022, 2023)
pg_unemployment_rate <- pg_unemployment_rate |> 
  filter(as.numeric(str_extract(date, "\\d{4}")) %in% multiple_years)
pg_unemployment_rate

#We got "NA" for some rows before we realized the original data didn't include those months, so we took them out.
pg_unemployment_notices <- left_join(pg_unemployment_rate, transposed_redo_2, join_by(date)) |> 
  filter(date!="January_2021" & date!="February_2021" & date!="March_2021" & date!="April_2021" & date!="May_2021" & date!="June_2021") |> 
  group_by(date, pg_unemployment) |> 
  select("20607", "20608", "20613", "20623", "20703", "20704", "20705", "20706", "20707", "20708", "20710", "20712", "20715", "20716", "20717", "20718", "20719", "20720", "20721", "20722", "20725", "20735", "20737", "20740", "20741", "20742", "20743", "20744", "20745", "20746", "20747", "20748", "20750", "20757", "20762", "20769", "20770", "20771", "20781", "20782", "20783", "20784", "20785", "20787", "20788")
pg_unemployment_notices

# These are the PG county zip codes that didn't exist in the original data: "20731", "20790", "20791", "20799", "20753", "20749", "20768", "20709", "20726", "20738", "20797", "20697", "20752", "20775", "20792"
```

Q5. What are the differences in foreclosure notices by season (warm months vs cold months)? The only full year we have is 2022, so let's look at that year to start.
**We're concerned about our ability to filter by month since the dates are in the column position.**

#Findings so far: Again, having trouble getting the months to show up at the bottom of the chart, but we found there is an incline over the span of the year -- meaning there were more notices in the colder months. However, there was a pretty big spike in the spring (it looks like the spring) before the notices dropped again. I would be interested in finding out more about that.

```{r}
#Here we are selecting only the 2022 months
foreclosures_2022 <- foreclosures |> 
  group_by(zip) |>
  select(ends_with("2"))

foreclosures_2022
```

```{r}
#Here we are transposing that 2022 data set to make it easier to add everything
transposed_foreclosures_2022 <- foreclosures_2022 |> 
  gather(Date, Value, -1) |> 
  spread(key = zip, value = Value) |> 
  mutate(month_year = as.yearmon(paste(Date, "01", sep = "_"), format="%B_%Y_%d"))

transposed_foreclosures_2022
```


```{r}
# Now for the adding
final_foreclosures_2022 <- transposed_foreclosures_2022[, c(ncol(transposed_foreclosures_2022), 1:(ncol(transposed_foreclosures_2022)-1))] |> 
  select(-Date) |> 
  arrange(month_year)

final_foreclosures_2022
```

```{r}
col_sum_2022_months <- final_foreclosures_2022 |> 
  mutate(sum_of_notices = rowSums(final_foreclosures_2022[,-1]))

foreclosures_by_month_2022 <- col_sum_2022_months[, c(ncol(transposed_foreclosures_2022), 1:(ncol(col_sum_2022_months)-1))] |>
  select(month_year, sum_of_notices)

foreclosures_by_month_2022
```

```{r}
#Checking for the same number on the first row
rowSums(foreclosures_by_month_2022[1,-1])
```

```{r}
# Time to chart. I'm having trouble getting the ticks and month labels for this, and Chat GPT said it's because of the data type of the month_year column. We need to change that column to a date type using the first day of every month.

foreclosures_by_month_2022 |> 
   ggplot() + 
  geom_line(aes(x= month_year, y=sum_of_notices)) +
  scale_x_continuous(breaks = 1:52) +
 labs(
    title="Intent to foreclose notices in Maryland across 2022",
    x = "month",
    y = "intent to foreclose notices issued",
    caption = "Source: Office of Financial Regulation") +
theme(
    axis.text.x = element_text(angle = 45,  hjust=1)) 

```
