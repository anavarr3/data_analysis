---
title: "data_analysis_EPA"
output: html_document
date: "2023-11-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dplyr)
library(janitor)
```
# Dataset: Maryland Notices of Intent to Foreclose (July 2021 - Oct. 2023)

```{r}
# Read in and clean the data
foreclosures <- read_csv("Maryland_Notices_of_Intent_to_Foreclose.csv") |> 
  clean_names() |> 
  rename(february_2022 = february_2020)
```
```{r}
# Results of code: 
foreclosures
```


```{r}
# Here we wanted to try and make a quick map to see what we were looking at other than just a table of numbers.
foreclosures_sum <- foreclosures |>
  group_by(zip) |>
  summarise(foreclosures_sum = sum(across(contains("_")))) |>
  arrange(desc(foreclosures_sum))

foreclosures_sum

write_csv(foreclosures_sum, "foreclosure_sum.csv")
```


Q2 How has this zip code changed over the timespan?
```{r}
foreclosures |> 
  filter(zip == 20772)
```

Q3. Join foreclosures_sum with census data (demographics) to answer

Q4. Limitations: can only look at the data for 2021 and 2022 to compare the holiday season foreclosures since the 2023 data is not in yet
```{r}
twoyearforeclosures <- foreclosures |> 
  select(ends_with("1", "2"))

twoyearforeclosures
```








